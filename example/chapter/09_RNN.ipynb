{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 96, 16) (700, 2)\n",
      "[[-0.19651586 -0.10735795 -0.57027595 ...  0.81843166 -0.65288486\n",
      "   0.13831083]\n",
      " [ 0.95872117  0.44811327  0.22441193 ...  0.65407623  0.20270836\n",
      "  -0.36168748]\n",
      " [ 0.01120725 -0.29253854  0.35298953 ... -1.00774508  0.8626005\n",
      "   0.63204357]\n",
      " ...\n",
      " [-0.82983572 -0.33686877 -0.13705201 ... -0.74389747  0.31126875\n",
      "  -0.80513672]\n",
      " [-0.75449754 -0.37745461 -0.3922741  ... -0.60842135 -1.17763147\n",
      "  -0.3696263 ]\n",
      " [ 0.07101136 -1.21775053 -0.80890495 ...  0.54379608 -0.3019266\n",
      "  -0.54774718]] [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "from data.generater import waveData\n",
    "\n",
    "seq_len = 96  # 序列长度\n",
    "in_dim = 16  # 输入维度\n",
    "state_dim = 12  # 状态维度\n",
    "\n",
    "xs, ys = waveData(1000, in_dim, seq_len)\n",
    "\n",
    "train_xs = xs[:700]\n",
    "train_ys = ys[:700]\n",
    "test_xs = xs[700:]\n",
    "test_ys = ys[700:]\n",
    "\n",
    "print(train_xs.shape, train_ys.shape)\n",
    "print(train_xs[0], train_ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, itet: 64, loss: 0.7011864.\n",
      "Epoch: 1, itet: 128, loss: 0.7243448.\n",
      "Epoch: 1, itet: 192, loss: 0.6664761.\n",
      "Epoch: 1, itet: 256, loss: 0.6662409.\n",
      "Epoch: 1, itet: 320, loss: 0.7237994.\n",
      "Epoch: 1, itet: 384, loss: 0.7207229.\n",
      "Epoch: 1, itet: 448, loss: 0.6667717.\n",
      "Epoch: 1, itet: 512, loss: 0.6709399.\n",
      "Epoch: 1, itet: 576, loss: 0.6785114.\n",
      "Epoch: 1, itet: 640, loss: 0.6963072.\n",
      "Epoch: 1, acc: 0.477.\n",
      "Epoch: 2, itet: 64, loss: 0.6653894.\n",
      "Epoch: 2, itet: 128, loss: 0.6694875.\n",
      "Epoch: 2, itet: 192, loss: 0.6234589.\n",
      "Epoch: 2, itet: 256, loss: 0.1756821.\n",
      "Epoch: 2, itet: 320, loss: 0.4252226.\n",
      "Epoch: 2, itet: 384, loss: 0.6880452.\n",
      "Epoch: 2, itet: 448, loss: 0.3213921.\n",
      "Epoch: 2, itet: 512, loss: 0.4237661.\n",
      "Epoch: 2, itet: 576, loss: 0.3314456.\n",
      "Epoch: 2, itet: 640, loss: 0.5297717.\n",
      "Epoch: 2, acc: 0.947.\n",
      "Epoch: 3, itet: 64, loss: 0.4432591.\n",
      "Epoch: 3, itet: 128, loss: 0.4441963.\n",
      "Epoch: 3, itet: 192, loss: 0.1682618.\n",
      "Epoch: 3, itet: 256, loss: 0.0350314.\n",
      "Epoch: 3, itet: 320, loss: 0.3645093.\n",
      "Epoch: 3, itet: 384, loss: 0.2800906.\n",
      "Epoch: 3, itet: 448, loss: 0.1019830.\n",
      "Epoch: 3, itet: 512, loss: 0.1472544.\n",
      "Epoch: 3, itet: 576, loss: 0.4384702.\n",
      "Epoch: 3, itet: 640, loss: 0.2179226.\n",
      "Epoch: 3, acc: 0.977.\n",
      "Epoch: 4, itet: 64, loss: 0.1604614.\n",
      "Epoch: 4, itet: 128, loss: 0.1778282.\n",
      "Epoch: 4, itet: 192, loss: 0.0389280.\n",
      "Epoch: 4, itet: 256, loss: 0.0025616.\n",
      "Epoch: 4, itet: 320, loss: 0.1374224.\n",
      "Epoch: 4, itet: 384, loss: 0.1012753.\n",
      "Epoch: 4, itet: 448, loss: 0.0282093.\n",
      "Epoch: 4, itet: 512, loss: 0.1095798.\n",
      "Epoch: 4, itet: 576, loss: 0.5275638.\n",
      "Epoch: 4, itet: 640, loss: 0.0888898.\n",
      "Epoch: 4, acc: 0.973.\n",
      "Epoch: 5, itet: 64, loss: 0.0589623.\n",
      "Epoch: 5, itet: 128, loss: 0.0684328.\n",
      "Epoch: 5, itet: 192, loss: 0.0027570.\n",
      "Epoch: 5, itet: 256, loss: 0.0029376.\n",
      "Epoch: 5, itet: 320, loss: 0.0524616.\n",
      "Epoch: 5, itet: 384, loss: 0.0466835.\n",
      "Epoch: 5, itet: 448, loss: 0.0038830.\n",
      "Epoch: 5, itet: 512, loss: 0.0766207.\n",
      "Epoch: 5, itet: 576, loss: 1.0765860.\n",
      "Epoch: 5, itet: 640, loss: 0.0436062.\n",
      "Epoch: 5, acc: 0.960.\n",
      "Epoch: 6, itet: 64, loss: 0.0337060.\n",
      "Epoch: 6, itet: 128, loss: 0.0347789.\n",
      "Epoch: 6, itet: 192, loss: 0.0039446.\n",
      "Epoch: 6, itet: 256, loss: 0.0003231.\n",
      "Epoch: 6, itet: 320, loss: 0.0310497.\n",
      "Epoch: 6, itet: 384, loss: 0.0277572.\n",
      "Epoch: 6, itet: 448, loss: 0.0055833.\n",
      "Epoch: 6, itet: 512, loss: 0.0165288.\n",
      "Epoch: 6, itet: 576, loss: 0.5557783.\n",
      "Epoch: 6, itet: 640, loss: 0.0231609.\n",
      "Epoch: 6, acc: 0.973.\n",
      "Epoch: 7, itet: 64, loss: 0.0206645.\n",
      "Epoch: 7, itet: 128, loss: 0.0211748.\n",
      "Epoch: 7, itet: 192, loss: 0.0067069.\n",
      "Epoch: 7, itet: 256, loss: 0.0004115.\n",
      "Epoch: 7, itet: 320, loss: 0.0188063.\n",
      "Epoch: 7, itet: 384, loss: 0.0177737.\n",
      "Epoch: 7, itet: 448, loss: 0.0044585.\n",
      "Epoch: 7, itet: 512, loss: 0.0229765.\n",
      "Epoch: 7, itet: 576, loss: 0.4704325.\n",
      "Epoch: 7, itet: 640, loss: 0.0147861.\n",
      "Epoch: 7, acc: 0.973.\n",
      "Epoch: 8, itet: 64, loss: 0.0134789.\n",
      "Epoch: 8, itet: 128, loss: 0.0136254.\n",
      "Epoch: 8, itet: 192, loss: 0.0047041.\n",
      "Epoch: 8, itet: 256, loss: 0.0003288.\n",
      "Epoch: 8, itet: 320, loss: 0.0124676.\n",
      "Epoch: 8, itet: 384, loss: 0.0124625.\n",
      "Epoch: 8, itet: 448, loss: 0.0030511.\n",
      "Epoch: 8, itet: 512, loss: 0.0136407.\n",
      "Epoch: 8, itet: 576, loss: 0.4029160.\n",
      "Epoch: 8, itet: 640, loss: 0.0100582.\n",
      "Epoch: 8, acc: 0.973.\n",
      "Epoch: 9, itet: 64, loss: 0.0097399.\n",
      "Epoch: 9, itet: 128, loss: 0.0099358.\n",
      "Epoch: 9, itet: 192, loss: 0.0036422.\n",
      "Epoch: 9, itet: 256, loss: 0.0003594.\n",
      "Epoch: 9, itet: 320, loss: 0.0099941.\n",
      "Epoch: 9, itet: 384, loss: 0.0107684.\n",
      "Epoch: 9, itet: 448, loss: 0.0003854.\n",
      "Epoch: 9, itet: 512, loss: 0.0000010.\n",
      "Epoch: 9, itet: 576, loss: 0.0871166.\n",
      "Epoch: 9, itet: 640, loss: 0.0078806.\n",
      "Epoch: 9, acc: 0.970.\n",
      "Epoch: 10, itet: 64, loss: 0.0125037.\n",
      "Epoch: 10, itet: 128, loss: 0.0158926.\n",
      "Epoch: 10, itet: 192, loss: 0.0028798.\n",
      "Epoch: 10, itet: 256, loss: 0.0050390.\n",
      "Epoch: 10, itet: 320, loss: 0.0128836.\n",
      "Epoch: 10, itet: 384, loss: 0.0146499.\n",
      "Epoch: 10, itet: 448, loss: 0.0006277.\n",
      "Epoch: 10, itet: 512, loss: 0.0030445.\n",
      "Epoch: 10, itet: 576, loss: 0.4959002.\n",
      "Epoch: 10, itet: 640, loss: 0.0123019.\n",
      "Epoch: 10, acc: 0.973.\n",
      "Epoch: 11, itet: 64, loss: 0.0129961.\n",
      "Epoch: 11, itet: 128, loss: 0.0149784.\n",
      "Epoch: 11, itet: 192, loss: 0.0009264.\n",
      "Epoch: 11, itet: 256, loss: 0.0011389.\n",
      "Epoch: 11, itet: 320, loss: 0.0114752.\n",
      "Epoch: 11, itet: 384, loss: 0.0126601.\n",
      "Epoch: 11, itet: 448, loss: 0.0018819.\n",
      "Epoch: 11, itet: 512, loss: 0.0014554.\n",
      "Epoch: 11, itet: 576, loss: 0.2019188.\n",
      "Epoch: 11, itet: 640, loss: 0.0101956.\n",
      "Epoch: 11, acc: 0.970.\n",
      "Epoch: 12, itet: 64, loss: 0.0109860.\n",
      "Epoch: 12, itet: 128, loss: 0.0133049.\n",
      "Epoch: 12, itet: 192, loss: 0.0007125.\n",
      "Epoch: 12, itet: 256, loss: 0.0014834.\n",
      "Epoch: 12, itet: 320, loss: 0.0097734.\n",
      "Epoch: 12, itet: 384, loss: 0.0111267.\n",
      "Epoch: 12, itet: 448, loss: 0.0013983.\n",
      "Epoch: 12, itet: 512, loss: 0.0013006.\n",
      "Epoch: 12, itet: 576, loss: 0.2065422.\n",
      "Epoch: 12, itet: 640, loss: 0.0089665.\n",
      "Epoch: 12, acc: 0.970.\n",
      "Epoch: 13, itet: 64, loss: 0.0098223.\n",
      "Epoch: 13, itet: 128, loss: 0.0120637.\n",
      "Epoch: 13, itet: 192, loss: 0.0006587.\n",
      "Epoch: 13, itet: 256, loss: 0.0013889.\n",
      "Epoch: 13, itet: 320, loss: 0.0087920.\n",
      "Epoch: 13, itet: 384, loss: 0.0100048.\n",
      "Epoch: 13, itet: 448, loss: 0.0013424.\n",
      "Epoch: 13, itet: 512, loss: 0.0011096.\n",
      "Epoch: 13, itet: 576, loss: 0.1850929.\n",
      "Epoch: 13, itet: 640, loss: 0.0081035.\n",
      "Epoch: 13, acc: 0.970.\n",
      "Epoch: 14, itet: 64, loss: 0.0089326.\n",
      "Epoch: 14, itet: 128, loss: 0.0111716.\n",
      "Epoch: 14, itet: 192, loss: 0.0005611.\n",
      "Epoch: 14, itet: 256, loss: 0.0012168.\n",
      "Epoch: 14, itet: 320, loss: 0.0080621.\n",
      "Epoch: 14, itet: 384, loss: 0.0091222.\n",
      "Epoch: 14, itet: 448, loss: 0.0012528.\n",
      "Epoch: 14, itet: 512, loss: 0.0008977.\n",
      "Epoch: 14, itet: 576, loss: 0.1618409.\n",
      "Epoch: 14, itet: 640, loss: 0.0074675.\n",
      "Epoch: 14, acc: 0.967.\n",
      "Epoch: 15, itet: 64, loss: 0.0082404.\n",
      "Epoch: 15, itet: 128, loss: 0.0105178.\n",
      "Epoch: 15, itet: 192, loss: 0.0004448.\n",
      "Epoch: 15, itet: 256, loss: 0.0009708.\n",
      "Epoch: 15, itet: 320, loss: 0.0075248.\n",
      "Epoch: 15, itet: 384, loss: 0.0084113.\n",
      "Epoch: 15, itet: 448, loss: 0.0011908.\n",
      "Epoch: 15, itet: 512, loss: 0.0006800.\n",
      "Epoch: 15, itet: 576, loss: 0.1325957.\n",
      "Epoch: 15, itet: 640, loss: 0.0070106.\n",
      "Epoch: 15, acc: 0.963.\n",
      "Epoch: 16, itet: 64, loss: 0.0076931.\n",
      "Epoch: 16, itet: 128, loss: 0.0101081.\n",
      "Epoch: 16, itet: 192, loss: 0.0002870.\n",
      "Epoch: 16, itet: 256, loss: 0.0006448.\n",
      "Epoch: 16, itet: 320, loss: 0.0071317.\n",
      "Epoch: 16, itet: 384, loss: 0.0078265.\n",
      "Epoch: 16, itet: 448, loss: 0.0012007.\n",
      "Epoch: 16, itet: 512, loss: 0.0004387.\n",
      "Epoch: 16, itet: 576, loss: 0.0893510.\n",
      "Epoch: 16, itet: 640, loss: 0.0067388.\n",
      "Epoch: 16, acc: 0.963.\n",
      "Epoch: 17, itet: 64, loss: 0.0072289.\n",
      "Epoch: 17, itet: 128, loss: 0.0096615.\n",
      "Epoch: 17, itet: 192, loss: 0.0001853.\n",
      "Epoch: 17, itet: 256, loss: 0.0000720.\n",
      "Epoch: 17, itet: 320, loss: 0.0074255.\n",
      "Epoch: 17, itet: 384, loss: 0.0074826.\n",
      "Epoch: 17, itet: 448, loss: 0.0036785.\n",
      "Epoch: 17, itet: 512, loss: 0.0011035.\n",
      "Epoch: 17, itet: 576, loss: 0.1139002.\n",
      "Epoch: 17, itet: 640, loss: 0.0066290.\n",
      "Epoch: 17, acc: 0.967.\n",
      "Epoch: 18, itet: 64, loss: 0.0067898.\n",
      "Epoch: 18, itet: 128, loss: 0.0088382.\n",
      "Epoch: 18, itet: 192, loss: 0.0002314.\n",
      "Epoch: 18, itet: 256, loss: 0.0003607.\n",
      "Epoch: 18, itet: 320, loss: 0.0064455.\n",
      "Epoch: 18, itet: 384, loss: 0.0067820.\n",
      "Epoch: 18, itet: 448, loss: 0.0010784.\n",
      "Epoch: 18, itet: 512, loss: 0.0003644.\n",
      "Epoch: 18, itet: 576, loss: 0.0522653.\n",
      "Epoch: 18, itet: 640, loss: 0.0064147.\n",
      "Epoch: 18, acc: 0.983.\n",
      "Epoch: 19, itet: 64, loss: 0.0068429.\n",
      "Epoch: 19, itet: 128, loss: 0.0078429.\n",
      "Epoch: 19, itet: 192, loss: 0.0016551.\n",
      "Epoch: 19, itet: 256, loss: 0.0006894.\n",
      "Epoch: 19, itet: 320, loss: 0.0065746.\n",
      "Epoch: 19, itet: 384, loss: 0.0065707.\n",
      "Epoch: 19, itet: 448, loss: 0.0014771.\n",
      "Epoch: 19, itet: 512, loss: 0.0023228.\n",
      "Epoch: 19, itet: 576, loss: 0.4246232.\n",
      "Epoch: 19, itet: 640, loss: 0.0057116.\n",
      "Epoch: 19, acc: 0.970.\n",
      "Epoch: 20, itet: 64, loss: 0.0059867.\n",
      "Epoch: 20, itet: 128, loss: 0.0072982.\n",
      "Epoch: 20, itet: 192, loss: 0.0012383.\n",
      "Epoch: 20, itet: 256, loss: 0.0009951.\n",
      "Epoch: 20, itet: 320, loss: 0.0058141.\n",
      "Epoch: 20, itet: 384, loss: 0.0060045.\n",
      "Epoch: 20, itet: 448, loss: 0.0013082.\n",
      "Epoch: 20, itet: 512, loss: 0.0024283.\n",
      "Epoch: 20, itet: 576, loss: 0.3597711.\n",
      "Epoch: 20, itet: 640, loss: 0.0052431.\n",
      "Epoch: 20, acc: 0.970.\n",
      "Epoch: 21, itet: 64, loss: 0.0055925.\n",
      "Epoch: 21, itet: 128, loss: 0.0069777.\n",
      "Epoch: 21, itet: 192, loss: 0.0013177.\n",
      "Epoch: 21, itet: 256, loss: 0.0012220.\n",
      "Epoch: 21, itet: 320, loss: 0.0054284.\n",
      "Epoch: 21, itet: 384, loss: 0.0056110.\n",
      "Epoch: 21, itet: 448, loss: 0.0012643.\n",
      "Epoch: 21, itet: 512, loss: 0.0020601.\n",
      "Epoch: 21, itet: 576, loss: 0.2879686.\n",
      "Epoch: 21, itet: 640, loss: 0.0049251.\n",
      "Epoch: 21, acc: 0.970.\n",
      "Epoch: 22, itet: 64, loss: 0.0053111.\n",
      "Epoch: 22, itet: 128, loss: 0.0068674.\n",
      "Epoch: 22, itet: 192, loss: 0.0011071.\n",
      "Epoch: 22, itet: 256, loss: 0.0013115.\n",
      "Epoch: 22, itet: 320, loss: 0.0051752.\n",
      "Epoch: 22, itet: 384, loss: 0.0053133.\n",
      "Epoch: 22, itet: 448, loss: 0.0011331.\n",
      "Epoch: 22, itet: 512, loss: 0.0014380.\n",
      "Epoch: 22, itet: 576, loss: 0.2218920.\n",
      "Epoch: 22, itet: 640, loss: 0.0047458.\n",
      "Epoch: 22, acc: 0.973.\n",
      "Epoch: 23, itet: 64, loss: 0.0051413.\n",
      "Epoch: 23, itet: 128, loss: 0.0069713.\n",
      "Epoch: 23, itet: 192, loss: 0.0007395.\n",
      "Epoch: 23, itet: 256, loss: 0.0011482.\n",
      "Epoch: 23, itet: 320, loss: 0.0050535.\n",
      "Epoch: 23, itet: 384, loss: 0.0051090.\n",
      "Epoch: 23, itet: 448, loss: 0.0010105.\n",
      "Epoch: 23, itet: 512, loss: 0.0008000.\n",
      "Epoch: 23, itet: 576, loss: 0.1450478.\n",
      "Epoch: 23, itet: 640, loss: 0.0047202.\n",
      "Epoch: 23, acc: 0.963.\n",
      "Epoch: 24, itet: 64, loss: 0.0050775.\n",
      "Epoch: 24, itet: 128, loss: 0.0073882.\n",
      "Epoch: 24, itet: 192, loss: 0.0003208.\n",
      "Epoch: 24, itet: 256, loss: 0.0006602.\n",
      "Epoch: 24, itet: 320, loss: 0.0050851.\n",
      "Epoch: 24, itet: 384, loss: 0.0050841.\n",
      "Epoch: 24, itet: 448, loss: 0.0011470.\n",
      "Epoch: 24, itet: 512, loss: 0.0003627.\n",
      "Epoch: 24, itet: 576, loss: 0.0694094.\n",
      "Epoch: 24, itet: 640, loss: 0.0049869.\n",
      "Epoch: 24, acc: 0.960.\n",
      "Epoch: 25, itet: 64, loss: 0.0050539.\n",
      "Epoch: 25, itet: 128, loss: 0.0075986.\n",
      "Epoch: 25, itet: 192, loss: 5.2775669.\n",
      "Epoch: 25, itet: 256, loss: 0.0000004.\n",
      "Epoch: 25, itet: 320, loss: 0.0099874.\n",
      "Epoch: 25, itet: 384, loss: 0.0075668.\n",
      "Epoch: 25, itet: 448, loss: 0.0178592.\n",
      "Epoch: 25, itet: 512, loss: 0.0085109.\n",
      "Epoch: 25, itet: 576, loss: 0.2417321.\n",
      "Epoch: 25, itet: 640, loss: 0.0085354.\n",
      "Epoch: 25, acc: 0.973.\n",
      "Epoch: 26, itet: 64, loss: 0.0074662.\n",
      "Epoch: 26, itet: 128, loss: 0.0098925.\n",
      "Epoch: 26, itet: 192, loss: 0.0019913.\n",
      "Epoch: 26, itet: 256, loss: 0.0003793.\n",
      "Epoch: 26, itet: 320, loss: 0.0079324.\n",
      "Epoch: 26, itet: 384, loss: 0.0076239.\n",
      "Epoch: 26, itet: 448, loss: 0.0012774.\n",
      "Epoch: 26, itet: 512, loss: 0.0024200.\n",
      "Epoch: 26, itet: 576, loss: 0.2991999.\n",
      "Epoch: 26, itet: 640, loss: 0.0068178.\n",
      "Epoch: 26, acc: 0.970.\n",
      "Epoch: 27, itet: 64, loss: 0.0063997.\n",
      "Epoch: 27, itet: 128, loss: 0.0089537.\n",
      "Epoch: 27, itet: 192, loss: 0.0012471.\n",
      "Epoch: 27, itet: 256, loss: 0.0006540.\n",
      "Epoch: 27, itet: 320, loss: 0.0069321.\n",
      "Epoch: 27, itet: 384, loss: 0.0065851.\n",
      "Epoch: 27, itet: 448, loss: 0.0004888.\n",
      "Epoch: 27, itet: 512, loss: 0.0025207.\n",
      "Epoch: 27, itet: 576, loss: 0.3451653.\n",
      "Epoch: 27, itet: 640, loss: 0.0063287.\n",
      "Epoch: 27, acc: 0.970.\n",
      "Epoch: 28, itet: 64, loss: 0.0059635.\n",
      "Epoch: 28, itet: 128, loss: 0.0085693.\n",
      "Epoch: 28, itet: 192, loss: 0.0017661.\n",
      "Epoch: 28, itet: 256, loss: 0.0008765.\n",
      "Epoch: 28, itet: 320, loss: 0.0060257.\n",
      "Epoch: 28, itet: 384, loss: 0.0056716.\n",
      "Epoch: 28, itet: 448, loss: 0.0004071.\n",
      "Epoch: 28, itet: 512, loss: 0.0008179.\n",
      "Epoch: 28, itet: 576, loss: 0.2316823.\n",
      "Epoch: 28, itet: 640, loss: 0.0051393.\n",
      "Epoch: 28, acc: 0.967.\n",
      "Epoch: 29, itet: 64, loss: 0.0055027.\n",
      "Epoch: 29, itet: 128, loss: 0.0085858.\n",
      "Epoch: 29, itet: 192, loss: 0.0009239.\n",
      "Epoch: 29, itet: 256, loss: 0.0024973.\n",
      "Epoch: 29, itet: 320, loss: 0.0053605.\n",
      "Epoch: 29, itet: 384, loss: 0.0052234.\n",
      "Epoch: 29, itet: 448, loss: 0.0000882.\n",
      "Epoch: 29, itet: 512, loss: 0.0003968.\n",
      "Epoch: 29, itet: 576, loss: 0.2606359.\n",
      "Epoch: 29, itet: 640, loss: 0.0046181.\n",
      "Epoch: 29, acc: 0.970.\n",
      "Epoch: 30, itet: 64, loss: 0.0052614.\n",
      "Epoch: 30, itet: 128, loss: 0.0118255.\n",
      "Epoch: 30, itet: 192, loss: 0.0000334.\n",
      "Epoch: 30, itet: 256, loss: 0.0008291.\n",
      "Epoch: 30, itet: 320, loss: 0.0047997.\n",
      "Epoch: 30, itet: 384, loss: 0.0047102.\n",
      "Epoch: 30, itet: 448, loss: 0.0000411.\n",
      "Epoch: 30, itet: 512, loss: 0.0000672.\n",
      "Epoch: 30, itet: 576, loss: 0.2173643.\n",
      "Epoch: 30, itet: 640, loss: 0.0041257.\n",
      "Epoch: 30, acc: 0.970.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "import numpy as np\n",
    "from mflow import core, ops, opts, lays\n",
    "\n",
    "# 超参数\n",
    "lr = 0.005\n",
    "epoch = 30\n",
    "batch_size = 16\n",
    "\n",
    "with core.NameScope(\"RNN\"):\n",
    "    # 初始化变量\n",
    "    inputs = [core.Variable(size=(in_dim, 1), trainable=False) for _ in range(seq_len)]\n",
    "    u = core.Variable(size=(state_dim, in_dim), trainable=True)\n",
    "    w = core.Variable(size=(state_dim, state_dim), trainable=True)\n",
    "    b = core.Variable(size=(state_dim, 1), trainable=True)\n",
    "    y = core.Variable(size=(2, 1), trainable=False)\n",
    "    last_step = None  # 上一步输出，第一步的话就设置为None\n",
    "    # 网络构建\n",
    "    for iv in inputs:\n",
    "        h = ops.Add(ops.MatMul(u, iv), b)\n",
    "        if last_step is not None:\n",
    "            h = ops.Add(ops.MatMul(w, last_step), h)\n",
    "        h = ops.ReLU(h)\n",
    "        last_step = h\n",
    "    fc_1 = lays.Linear(last_step, state_dim, 40, \"ReLU\")\n",
    "    fc_2 = lays.Linear(fc_1, 40, 10, \"ReLU\")\n",
    "    pred = lays.Linear(fc_2, 10, 2, None)\n",
    "    predicter = ops.Logistic(pred)\n",
    "    loss = ops.loss.CrossEntropyWithSoftMax(pred, y)\n",
    "    loss.eps = 1e-8  # 避免梯度消失\n",
    "    adam = opts.Adam(core.DefaultGraph, loss, lr)\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        bs_idx = 0  # 批次计数\n",
    "        # 这是一个epoch的过程\n",
    "        for i, (feat, lab) in enumerate(zip(train_xs, train_ys)):\n",
    "            for j, x in enumerate(inputs):\n",
    "                x.setValue(np.mat(feat[j]).T)\n",
    "            y.setValue(np.mat(lab).T)\n",
    "            adam.step()\n",
    "            bs_idx += 1\n",
    "            if bs_idx == batch_size:\n",
    "                if (i + 1) % 64 == 0:\n",
    "                    print(\"Epoch: {:d}, itet: {:d}, loss: {:.7f}.\".format(\n",
    "                        ep, i + 1, loss.value[0, 0]))\n",
    "                adam.update()\n",
    "                bs_idx = 0\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for feat in test_xs:\n",
    "            for j, x in enumerate(inputs):\n",
    "                x.setValue(np.mat(feat[j]).T)\n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value.A.ravel())  # 结果\n",
    "        preds = np.array(preds).argmax(axis=1)\n",
    "        trues = test_ys.argmax(axis=1)\n",
    "        acc = (trues == preds).astype(\"uint8\").sum() / len(test_xs)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25450dffbd8ff6afdb60e6b8570ed9b7d168b4425452c653cc1a70a36de1a45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
