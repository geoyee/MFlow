{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 96, 16) (700, 2)\n",
      "[[ 0.70067267  1.09767075  1.71046556 ...  1.44020269  1.42304338\n",
      "   1.24774039]\n",
      " [ 0.2938712   0.85894091  2.01797972 ...  0.75407059  0.93394378\n",
      "   1.59527254]\n",
      " [ 1.38295959  1.71432963  1.10100853 ...  0.58260669  2.42027676\n",
      "   2.33753907]\n",
      " ...\n",
      " [-0.11892027 -1.10122582 -1.38127633 ... -1.28338248  0.08651137\n",
      "  -2.50751836]\n",
      " [-0.00366689 -0.90429202  0.08133322 ... -0.72773929 -0.63553461\n",
      "  -0.37435678]\n",
      " [-0.28939092 -1.65019108 -1.23763818 ...  0.15221053 -1.90733885\n",
      "  -0.41478961]] [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "from data.generater import waveData\n",
    "\n",
    "seq_len = 96  # 序列长度\n",
    "in_dim = 16  # 输入维度\n",
    "state_dim = 12  # 状态维度\n",
    "\n",
    "xs, ys = waveData(1000, in_dim, seq_len)\n",
    "\n",
    "train_xs = xs[:700]\n",
    "train_ys = ys[:700]\n",
    "test_xs = xs[700:]\n",
    "test_ys = ys[700:]\n",
    "\n",
    "print(train_xs.shape, train_ys.shape)\n",
    "print(train_xs[0], train_ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, itet: 64, loss: 0.7083669.\n",
      "Epoch: 1, itet: 128, loss: 0.6639147.\n",
      "Epoch: 1, itet: 192, loss: 0.6552973.\n",
      "Epoch: 1, itet: 256, loss: 0.6511815.\n",
      "Epoch: 1, itet: 320, loss: 0.7392856.\n",
      "Epoch: 1, itet: 384, loss: 0.7383916.\n",
      "Epoch: 1, itet: 448, loss: 0.6777211.\n",
      "Epoch: 1, itet: 512, loss: 0.7561344.\n",
      "Epoch: 1, itet: 576, loss: 1.0101479.\n",
      "Epoch: 1, itet: 640, loss: 0.8131289.\n",
      "Epoch: 1, acc: 0.893.\n",
      "Epoch: 2, itet: 64, loss: 0.2841931.\n",
      "Epoch: 2, itet: 128, loss: 0.1043078.\n",
      "Epoch: 2, itet: 192, loss: 0.0004203.\n",
      "Epoch: 2, itet: 256, loss: 0.0000745.\n",
      "Epoch: 2, itet: 320, loss: 0.0000045.\n",
      "Epoch: 2, itet: 384, loss: 0.0000002.\n",
      "Epoch: 2, itet: 448, loss: -0.0000000.\n",
      "Epoch: 2, itet: 512, loss: -0.0000000.\n",
      "Epoch: 2, itet: 576, loss: -0.0000000.\n",
      "Epoch: 2, itet: 640, loss: -0.0000000.\n",
      "Epoch: 2, acc: 1.000.\n",
      "Epoch: 3, itet: 64, loss: 0.0000013.\n",
      "Epoch: 3, itet: 128, loss: -0.0000000.\n",
      "Epoch: 3, itet: 192, loss: -0.0000000.\n",
      "Epoch: 3, itet: 256, loss: -0.0000000.\n",
      "Epoch: 3, itet: 320, loss: -0.0000000.\n",
      "Epoch: 3, itet: 384, loss: -0.0000000.\n",
      "Epoch: 3, itet: 448, loss: -0.0000000.\n",
      "Epoch: 3, itet: 512, loss: -0.0000000.\n",
      "Epoch: 3, itet: 576, loss: -0.0000000.\n",
      "Epoch: 3, itet: 640, loss: -0.0000000.\n",
      "Epoch: 3, acc: 1.000.\n",
      "Epoch: 4, itet: 64, loss: -0.0000000.\n",
      "Epoch: 4, itet: 128, loss: -0.0000000.\n",
      "Epoch: 4, itet: 192, loss: -0.0000000.\n",
      "Epoch: 4, itet: 256, loss: -0.0000000.\n",
      "Epoch: 4, itet: 320, loss: -0.0000000.\n",
      "Epoch: 4, itet: 384, loss: -0.0000000.\n",
      "Epoch: 4, itet: 448, loss: -0.0000000.\n",
      "Epoch: 4, itet: 512, loss: -0.0000000.\n",
      "Epoch: 4, itet: 576, loss: -0.0000000.\n",
      "Epoch: 4, itet: 640, loss: -0.0000000.\n",
      "Epoch: 4, acc: 1.000.\n",
      "Epoch: 5, itet: 64, loss: -0.0000000.\n",
      "Epoch: 5, itet: 128, loss: -0.0000000.\n",
      "Epoch: 5, itet: 192, loss: -0.0000000.\n",
      "Epoch: 5, itet: 256, loss: -0.0000000.\n",
      "Epoch: 5, itet: 320, loss: -0.0000000.\n",
      "Epoch: 5, itet: 384, loss: -0.0000000.\n",
      "Epoch: 5, itet: 448, loss: -0.0000000.\n",
      "Epoch: 5, itet: 512, loss: -0.0000000.\n",
      "Epoch: 5, itet: 576, loss: -0.0000000.\n",
      "Epoch: 5, itet: 640, loss: -0.0000000.\n",
      "Epoch: 5, acc: 1.000.\n",
      "Epoch: 6, itet: 64, loss: -0.0000000.\n",
      "Epoch: 6, itet: 128, loss: -0.0000000.\n",
      "Epoch: 6, itet: 192, loss: -0.0000000.\n",
      "Epoch: 6, itet: 256, loss: -0.0000000.\n",
      "Epoch: 6, itet: 320, loss: -0.0000000.\n",
      "Epoch: 6, itet: 384, loss: -0.0000000.\n",
      "Epoch: 6, itet: 448, loss: -0.0000000.\n",
      "Epoch: 6, itet: 512, loss: -0.0000000.\n",
      "Epoch: 6, itet: 576, loss: -0.0000000.\n",
      "Epoch: 6, itet: 640, loss: -0.0000000.\n",
      "Epoch: 6, acc: 1.000.\n",
      "Epoch: 7, itet: 64, loss: -0.0000000.\n",
      "Epoch: 7, itet: 128, loss: -0.0000000.\n",
      "Epoch: 7, itet: 192, loss: -0.0000000.\n",
      "Epoch: 7, itet: 256, loss: -0.0000000.\n",
      "Epoch: 7, itet: 320, loss: -0.0000000.\n",
      "Epoch: 7, itet: 384, loss: -0.0000000.\n",
      "Epoch: 7, itet: 448, loss: -0.0000000.\n",
      "Epoch: 7, itet: 512, loss: -0.0000000.\n",
      "Epoch: 7, itet: 576, loss: -0.0000000.\n",
      "Epoch: 7, itet: 640, loss: -0.0000000.\n",
      "Epoch: 7, acc: 1.000.\n",
      "Epoch: 8, itet: 64, loss: -0.0000000.\n",
      "Epoch: 8, itet: 128, loss: -0.0000000.\n",
      "Epoch: 8, itet: 192, loss: -0.0000000.\n",
      "Epoch: 8, itet: 256, loss: -0.0000000.\n",
      "Epoch: 8, itet: 320, loss: -0.0000000.\n",
      "Epoch: 8, itet: 384, loss: -0.0000000.\n",
      "Epoch: 8, itet: 448, loss: -0.0000000.\n",
      "Epoch: 8, itet: 512, loss: -0.0000000.\n",
      "Epoch: 8, itet: 576, loss: -0.0000000.\n",
      "Epoch: 8, itet: 640, loss: -0.0000000.\n",
      "Epoch: 8, acc: 1.000.\n",
      "Epoch: 9, itet: 64, loss: -0.0000000.\n",
      "Epoch: 9, itet: 128, loss: -0.0000000.\n",
      "Epoch: 9, itet: 192, loss: -0.0000000.\n",
      "Epoch: 9, itet: 256, loss: -0.0000000.\n",
      "Epoch: 9, itet: 320, loss: -0.0000000.\n",
      "Epoch: 9, itet: 384, loss: -0.0000000.\n",
      "Epoch: 9, itet: 448, loss: -0.0000000.\n",
      "Epoch: 9, itet: 512, loss: -0.0000000.\n",
      "Epoch: 9, itet: 576, loss: -0.0000000.\n",
      "Epoch: 9, itet: 640, loss: -0.0000000.\n",
      "Epoch: 9, acc: 1.000.\n",
      "Epoch: 10, itet: 64, loss: -0.0000000.\n",
      "Epoch: 10, itet: 128, loss: -0.0000000.\n",
      "Epoch: 10, itet: 192, loss: -0.0000000.\n",
      "Epoch: 10, itet: 256, loss: -0.0000000.\n",
      "Epoch: 10, itet: 320, loss: -0.0000000.\n",
      "Epoch: 10, itet: 384, loss: -0.0000000.\n",
      "Epoch: 10, itet: 448, loss: -0.0000000.\n",
      "Epoch: 10, itet: 512, loss: -0.0000000.\n",
      "Epoch: 10, itet: 576, loss: -0.0000000.\n",
      "Epoch: 10, itet: 640, loss: -0.0000000.\n",
      "Epoch: 10, acc: 1.000.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "import numpy as np\n",
    "from mflow import core, ops, opts, lays\n",
    "\n",
    "# 超参数\n",
    "lr = 0.005\n",
    "epoch = 10  # 30\n",
    "batch_size = 16\n",
    "\n",
    "with core.NameScope(\"RNN\"):\n",
    "    # 初始化变量\n",
    "    inputs = [core.Variable(size=(in_dim, 1), trainable=False) for _ in range(seq_len)]\n",
    "    u = core.Variable(size=(state_dim, in_dim), trainable=True)\n",
    "    w = core.Variable(size=(state_dim, state_dim), trainable=True)\n",
    "    b = core.Variable(size=(state_dim, 1), trainable=True)\n",
    "    y = core.Variable(size=(2, 1), trainable=False)\n",
    "    last_step = None  # 上一步输出，第一步的话就设置为None\n",
    "    # 网络构建\n",
    "    for iv in inputs:\n",
    "        h = ops.Add(ops.MatMul(u, iv), b)\n",
    "        if last_step is not None:\n",
    "            h = ops.Add(ops.MatMul(w, last_step), h)\n",
    "        h = ops.ReLU(h)\n",
    "        last_step = h\n",
    "    fc_1 = lays.Linear(last_step, state_dim, 40, \"ReLU\")\n",
    "    fc_2 = lays.Linear(fc_1, 40, 10, \"ReLU\")\n",
    "    pred = lays.Linear(fc_2, 10, 2, None)\n",
    "    predicter = ops.Logistic(pred)\n",
    "    loss = ops.loss.CrossEntropyWithSoftMax(pred, y)\n",
    "    adam = opts.Adam(core.DefaultGraph, loss, lr)\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        bs_idx = 0  # 批次计数\n",
    "        # 这是一个epoch的过程\n",
    "        for i, (feat, lab) in enumerate(zip(train_xs, train_ys)):\n",
    "            for j, x in enumerate(inputs):\n",
    "                x.setValue(np.mat(feat[j]).T)\n",
    "            y.setValue(np.mat(lab).T)\n",
    "            adam.step()\n",
    "            bs_idx += 1\n",
    "            if bs_idx == batch_size:\n",
    "                if (i + 1) % 64 == 0:\n",
    "                    print(\"Epoch: {:d}, itet: {:d}, loss: {:.7f}.\".format(\n",
    "                        ep, i + 1, loss.value[0, 0]))\n",
    "                adam.update()\n",
    "                bs_idx = 0\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for feat in test_xs:\n",
    "            for j, x in enumerate(inputs):\n",
    "                x.setValue(np.mat(feat[j]).T)\n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value.A.ravel())  # 结果\n",
    "        preds = np.array(preds).argmax(axis=1)\n",
    "        trues = test_ys.argmax(axis=1)\n",
    "        acc = (trues == preds).astype(\"uint8\").sum() / len(test_xs)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e464fba058b7062b0b3c4c12c3de33306c3fff5b5acf1746fee001474633a95"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
