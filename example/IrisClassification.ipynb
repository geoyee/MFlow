{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 3)\n",
      "[5.8 2.7 5.1 1.9] [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# TODO: 不使用pandas以及sklearn\n",
    "\n",
    "# 数据读取，并去掉第一列\n",
    "data = pd.read_csv(\"E:/dataFiles/github/MFlow/asset/Iris.csv\").drop(\"Id\", axis=1)\n",
    "# 打乱样本\n",
    "data = data.sample(len(data), replace=False)\n",
    "xs = data[[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]].values\n",
    "# 将字符串标签替换为数字\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(data[\"Species\"])\n",
    "# 转换为one-hot\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ys = ohe.fit_transform(label.reshape(-1, 1))\n",
    "\n",
    "print(xs.shape, ys.shape)\n",
    "print(xs[0], ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, acc: 0.667.\n",
      "Epoch: 2, acc: 0.667.\n",
      "Epoch: 3, acc: 0.960.\n",
      "Epoch: 4, acc: 0.673.\n",
      "Epoch: 5, acc: 0.947.\n",
      "Epoch: 6, acc: 0.840.\n",
      "Epoch: 7, acc: 0.927.\n",
      "Epoch: 8, acc: 0.907.\n",
      "Epoch: 9, acc: 0.933.\n",
      "Epoch: 10, acc: 0.940.\n",
      "Epoch: 11, acc: 0.947.\n",
      "Epoch: 12, acc: 0.940.\n",
      "Epoch: 13, acc: 0.940.\n",
      "Epoch: 14, acc: 0.940.\n",
      "Epoch: 15, acc: 0.953.\n",
      "Epoch: 16, acc: 0.953.\n",
      "Epoch: 17, acc: 0.953.\n",
      "Epoch: 18, acc: 0.953.\n",
      "Epoch: 19, acc: 0.953.\n",
      "Epoch: 20, acc: 0.953.\n",
      "Epoch: 21, acc: 0.953.\n",
      "Epoch: 22, acc: 0.960.\n",
      "Epoch: 23, acc: 0.967.\n",
      "Epoch: 24, acc: 0.967.\n",
      "Epoch: 25, acc: 0.967.\n",
      "Epoch: 26, acc: 0.960.\n",
      "Epoch: 27, acc: 0.960.\n",
      "Epoch: 28, acc: 0.960.\n",
      "Epoch: 29, acc: 0.960.\n",
      "Epoch: 30, acc: 0.960.\n",
      "Epoch: 31, acc: 0.960.\n",
      "Epoch: 32, acc: 0.960.\n",
      "Epoch: 33, acc: 0.960.\n",
      "Epoch: 34, acc: 0.960.\n",
      "Epoch: 35, acc: 0.960.\n",
      "Epoch: 36, acc: 0.960.\n",
      "Epoch: 37, acc: 0.960.\n",
      "Epoch: 38, acc: 0.960.\n",
      "Epoch: 39, acc: 0.960.\n",
      "Epoch: 40, acc: 0.960.\n",
      "Epoch: 41, acc: 0.960.\n",
      "Epoch: 42, acc: 0.960.\n",
      "Epoch: 43, acc: 0.960.\n",
      "Epoch: 44, acc: 0.960.\n",
      "Epoch: 45, acc: 0.967.\n",
      "Epoch: 46, acc: 0.967.\n",
      "Epoch: 47, acc: 0.967.\n",
      "Epoch: 48, acc: 0.967.\n",
      "Epoch: 49, acc: 0.967.\n",
      "Epoch: 50, acc: 0.967.\n",
      "Epoch: 51, acc: 0.967.\n",
      "Epoch: 52, acc: 0.967.\n",
      "Epoch: 53, acc: 0.967.\n",
      "Epoch: 54, acc: 0.967.\n",
      "Epoch: 55, acc: 0.967.\n",
      "Epoch: 56, acc: 0.967.\n",
      "Epoch: 57, acc: 0.967.\n",
      "Epoch: 58, acc: 0.967.\n",
      "Epoch: 59, acc: 0.967.\n",
      "Epoch: 60, acc: 0.967.\n",
      "Epoch: 61, acc: 0.960.\n",
      "Epoch: 62, acc: 0.960.\n",
      "Epoch: 63, acc: 0.960.\n",
      "Epoch: 64, acc: 0.960.\n",
      "Epoch: 65, acc: 0.960.\n",
      "Epoch: 66, acc: 0.960.\n",
      "Epoch: 67, acc: 0.960.\n",
      "Epoch: 68, acc: 0.960.\n",
      "Epoch: 69, acc: 0.960.\n",
      "Epoch: 70, acc: 0.960.\n",
      "Epoch: 71, acc: 0.960.\n",
      "Epoch: 72, acc: 0.960.\n",
      "Epoch: 73, acc: 0.960.\n",
      "Epoch: 74, acc: 0.960.\n",
      "Epoch: 75, acc: 0.960.\n",
      "Epoch: 76, acc: 0.960.\n",
      "Epoch: 77, acc: 0.960.\n",
      "Epoch: 78, acc: 0.960.\n",
      "Epoch: 79, acc: 0.953.\n",
      "Epoch: 80, acc: 0.953.\n",
      "Epoch: 81, acc: 0.953.\n",
      "Epoch: 82, acc: 0.953.\n",
      "Epoch: 83, acc: 0.953.\n",
      "Epoch: 84, acc: 0.953.\n",
      "Epoch: 85, acc: 0.953.\n",
      "Epoch: 86, acc: 0.953.\n",
      "Epoch: 87, acc: 0.953.\n",
      "Epoch: 88, acc: 0.953.\n",
      "Epoch: 89, acc: 0.953.\n",
      "Epoch: 90, acc: 0.953.\n",
      "Epoch: 91, acc: 0.953.\n",
      "Epoch: 92, acc: 0.953.\n",
      "Epoch: 93, acc: 0.953.\n",
      "Epoch: 94, acc: 0.953.\n",
      "Epoch: 95, acc: 0.953.\n",
      "Epoch: 96, acc: 0.953.\n",
      "Epoch: 97, acc: 0.953.\n",
      "Epoch: 98, acc: 0.953.\n",
      "Epoch: 99, acc: 0.953.\n",
      "Epoch: 100, acc: 0.953.\n",
      "Epoch: 101, acc: 0.953.\n",
      "Epoch: 102, acc: 0.953.\n",
      "Epoch: 103, acc: 0.953.\n",
      "Epoch: 104, acc: 0.953.\n",
      "Epoch: 105, acc: 0.953.\n",
      "Epoch: 106, acc: 0.953.\n",
      "Epoch: 107, acc: 0.953.\n",
      "Epoch: 108, acc: 0.953.\n",
      "Epoch: 109, acc: 0.953.\n",
      "Epoch: 110, acc: 0.953.\n",
      "Epoch: 111, acc: 0.953.\n",
      "Epoch: 112, acc: 0.953.\n",
      "Epoch: 113, acc: 0.953.\n",
      "Epoch: 114, acc: 0.953.\n",
      "Epoch: 115, acc: 0.953.\n",
      "Epoch: 116, acc: 0.953.\n",
      "Epoch: 117, acc: 0.953.\n",
      "Epoch: 118, acc: 0.953.\n",
      "Epoch: 119, acc: 0.953.\n",
      "Epoch: 120, acc: 0.953.\n",
      "Epoch: 121, acc: 0.953.\n",
      "Epoch: 122, acc: 0.953.\n",
      "Epoch: 123, acc: 0.953.\n",
      "Epoch: 124, acc: 0.953.\n",
      "Epoch: 125, acc: 0.953.\n",
      "Epoch: 126, acc: 0.953.\n",
      "Epoch: 127, acc: 0.953.\n",
      "Epoch: 128, acc: 0.953.\n",
      "Epoch: 129, acc: 0.953.\n",
      "Epoch: 130, acc: 0.953.\n",
      "Epoch: 131, acc: 0.953.\n",
      "Epoch: 132, acc: 0.953.\n",
      "Epoch: 133, acc: 0.953.\n",
      "Epoch: 134, acc: 0.953.\n",
      "Epoch: 135, acc: 0.953.\n",
      "Epoch: 136, acc: 0.953.\n",
      "Epoch: 137, acc: 0.953.\n",
      "Epoch: 138, acc: 0.953.\n",
      "Epoch: 139, acc: 0.953.\n",
      "Epoch: 140, acc: 0.953.\n",
      "Epoch: 141, acc: 0.953.\n",
      "Epoch: 142, acc: 0.953.\n",
      "Epoch: 143, acc: 0.953.\n",
      "Epoch: 144, acc: 0.953.\n",
      "Epoch: 145, acc: 0.953.\n",
      "Epoch: 146, acc: 0.953.\n",
      "Epoch: 147, acc: 0.953.\n",
      "Epoch: 148, acc: 0.953.\n",
      "Epoch: 149, acc: 0.953.\n",
      "Epoch: 150, acc: 0.953.\n",
      "Epoch: 151, acc: 0.953.\n",
      "Epoch: 152, acc: 0.953.\n",
      "Epoch: 153, acc: 0.953.\n",
      "Epoch: 154, acc: 0.953.\n",
      "Epoch: 155, acc: 0.953.\n",
      "Epoch: 156, acc: 0.953.\n",
      "Epoch: 157, acc: 0.953.\n",
      "Epoch: 158, acc: 0.953.\n",
      "Epoch: 159, acc: 0.953.\n",
      "Epoch: 160, acc: 0.953.\n",
      "Epoch: 161, acc: 0.953.\n",
      "Epoch: 162, acc: 0.953.\n",
      "Epoch: 163, acc: 0.953.\n",
      "Epoch: 164, acc: 0.953.\n",
      "Epoch: 165, acc: 0.953.\n",
      "Epoch: 166, acc: 0.953.\n",
      "Epoch: 167, acc: 0.953.\n",
      "Epoch: 168, acc: 0.953.\n",
      "Epoch: 169, acc: 0.953.\n",
      "Epoch: 170, acc: 0.953.\n",
      "Epoch: 171, acc: 0.953.\n",
      "Epoch: 172, acc: 0.953.\n",
      "Epoch: 173, acc: 0.953.\n",
      "Epoch: 174, acc: 0.953.\n",
      "Epoch: 175, acc: 0.953.\n",
      "Epoch: 176, acc: 0.953.\n",
      "Epoch: 177, acc: 0.953.\n",
      "Epoch: 178, acc: 0.953.\n",
      "Epoch: 179, acc: 0.953.\n",
      "Epoch: 180, acc: 0.953.\n",
      "Epoch: 181, acc: 0.953.\n",
      "Epoch: 182, acc: 0.953.\n",
      "Epoch: 183, acc: 0.953.\n",
      "Epoch: 184, acc: 0.953.\n",
      "Epoch: 185, acc: 0.953.\n",
      "Epoch: 186, acc: 0.953.\n",
      "Epoch: 187, acc: 0.953.\n",
      "Epoch: 188, acc: 0.953.\n",
      "Epoch: 189, acc: 0.953.\n",
      "Epoch: 190, acc: 0.953.\n",
      "Epoch: 191, acc: 0.953.\n",
      "Epoch: 192, acc: 0.953.\n",
      "Epoch: 193, acc: 0.953.\n",
      "Epoch: 194, acc: 0.953.\n",
      "Epoch: 195, acc: 0.953.\n",
      "Epoch: 196, acc: 0.953.\n",
      "Epoch: 197, acc: 0.953.\n",
      "Epoch: 198, acc: 0.953.\n",
      "Epoch: 199, acc: 0.953.\n",
      "Epoch: 200, acc: 0.953.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from mflow import core, ops, opt\n",
    "\n",
    "# 超参数\n",
    "lr = 0.02\n",
    "epoch = 200\n",
    "batch_size = 16\n",
    "\n",
    "with core.NameScope(\"IrisClassification\"):\n",
    "    # 初始化变量\n",
    "    x = core.Variable(size=(4, 1), trainable=False)\n",
    "    y = core.Variable(size=(3, 1), trainable=False)\n",
    "    w = core.Variable(size=(3, 4), trainable=True)\n",
    "    b = core.Variable(size=(3, 1), trainable=True)\n",
    "    # 模型定义\n",
    "    pred = ops.Add(ops.MatMal(w, x), b)\n",
    "    predicter = ops.SoftMax(pred)\n",
    "    loss = ops.loss.CrossEntropyWithSoftMax(pred, y)\n",
    "    adam = opt.Adam(core.DefaultGraph, loss, lr)\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        bs_idx = 0  # 批次计数\n",
    "        # 这是一个epoch的过程\n",
    "        for i, (feat, one_hot) in enumerate(zip(xs, ys)):\n",
    "            x.setValue(np.mat(feat).T)\n",
    "            y.setValue(np.mat(one_hot).T)\n",
    "            adam.step()\n",
    "            bs_idx += 1\n",
    "            if bs_idx == batch_size:\n",
    "                adam.update()\n",
    "                bs_idx = 0\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for feat in xs:\n",
    "            x.setValue(np.mat(feat).T)\n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value.A.ravel())  # 结果\n",
    "        preds = np.array(preds).argmax(axis=1)\n",
    "        acc = (label == preds).astype(\"uint8\").sum() / len(xs)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25450dffbd8ff6afdb60e6b8570ed9b7d168b4425452c653cc1a70a36de1a45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
