{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Welding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 96, 16) (700, 2)\n",
      "[[-0.47902943 -0.33888471 -0.15164262 ...  0.29760411  0.08401242\n",
      "   0.6191582 ]\n",
      " [ 0.56697832 -1.08823451  0.24312622 ...  1.38201263  0.60539122\n",
      "   0.08490446]\n",
      " [-0.74879086  0.20460376  0.34146502 ...  0.37672354 -0.38006992\n",
      "   0.25312174]\n",
      " ...\n",
      " [ 0.79162252 -0.6409203  -0.01049418 ... -0.66999013  0.43906847\n",
      "  -0.65729462]\n",
      " [-1.32582854  0.31737572  0.71984772 ... -1.16742353 -1.10996313\n",
      "  -0.67468318]\n",
      " [-0.38289001 -1.70425701 -0.4322597  ...  0.00871695 -1.11056038\n",
      "  -0.37275389]] [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "from data.generater import waveData\n",
    "\n",
    "seq_len = 96  # 序列长度\n",
    "in_dim = 16  # 输入维度\n",
    "state_dim = 12  # 状态维度\n",
    "\n",
    "xs, ys = waveData(1000, in_dim, seq_len)\n",
    "\n",
    "train_xs = xs[:700]\n",
    "train_ys = ys[:700]\n",
    "test_xs = xs[700:]\n",
    "test_ys = ys[700:]\n",
    "\n",
    "print(train_xs.shape, train_ys.shape)\n",
    "print(train_xs[0], train_ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, itet: 64, loss: 0.6957231.\n",
      "Epoch: 1, itet: 128, loss: 0.6877459.\n",
      "Epoch: 1, itet: 192, loss: 0.7096018.\n",
      "Epoch: 1, itet: 256, loss: 0.7158942.\n",
      "Epoch: 1, itet: 320, loss: 0.6733113.\n",
      "Epoch: 1, itet: 384, loss: 0.6466772.\n",
      "Epoch: 1, itet: 448, loss: 0.7469688.\n",
      "Epoch: 1, itet: 512, loss: 0.6260917.\n",
      "Epoch: 1, itet: 576, loss: 0.7846410.\n",
      "Epoch: 1, itet: 640, loss: 0.8065098.\n",
      "Epoch: 1, acc: 0.470.\n",
      "Epoch: 2, itet: 64, loss: 0.1719376.\n",
      "Epoch: 2, itet: 128, loss: 0.6756439.\n",
      "Epoch: 2, itet: 192, loss: 0.9503417.\n",
      "Epoch: 2, itet: 256, loss: 0.6805741.\n",
      "Epoch: 2, itet: 320, loss: 0.4258916.\n",
      "Epoch: 2, itet: 384, loss: 0.2345144.\n",
      "Epoch: 2, itet: 448, loss: 0.0479421.\n",
      "Epoch: 2, itet: 512, loss: 0.7575343.\n",
      "Epoch: 2, itet: 576, loss: 0.0099397.\n",
      "Epoch: 2, itet: 640, loss: 0.4588063.\n",
      "Epoch: 2, acc: 0.777.\n",
      "Epoch: 3, itet: 64, loss: 1.1665633.\n",
      "Epoch: 3, itet: 128, loss: 0.0009733.\n",
      "Epoch: 3, itet: 192, loss: 1.7433162.\n",
      "Epoch: 3, itet: 256, loss: 0.0020654.\n",
      "Epoch: 3, itet: 320, loss: 0.3440103.\n",
      "Epoch: 3, itet: 384, loss: 0.2593586.\n",
      "Epoch: 3, itet: 448, loss: 0.0064036.\n",
      "Epoch: 3, itet: 512, loss: 0.3232462.\n",
      "Epoch: 3, itet: 576, loss: 1.0557704.\n",
      "Epoch: 3, itet: 640, loss: 1.2364450.\n",
      "Epoch: 3, acc: 0.793.\n",
      "Epoch: 4, itet: 64, loss: 0.3329308.\n",
      "Epoch: 4, itet: 128, loss: 0.6325608.\n",
      "Epoch: 4, itet: 192, loss: 2.0378113.\n",
      "Epoch: 4, itet: 256, loss: 0.0011273.\n",
      "Epoch: 4, itet: 320, loss: 0.0782510.\n",
      "Epoch: 4, itet: 384, loss: 0.0898382.\n",
      "Epoch: 4, itet: 448, loss: 0.0041335.\n",
      "Epoch: 4, itet: 512, loss: 0.3849479.\n",
      "Epoch: 4, itet: 576, loss: 0.7454749.\n",
      "Epoch: 4, itet: 640, loss: 0.0041468.\n",
      "Epoch: 4, acc: 0.707.\n",
      "Epoch: 5, itet: 64, loss: 0.6706317.\n",
      "Epoch: 5, itet: 128, loss: 0.7012634.\n",
      "Epoch: 5, itet: 192, loss: 0.0012681.\n",
      "Epoch: 5, itet: 256, loss: 0.0071454.\n",
      "Epoch: 5, itet: 320, loss: 0.2755304.\n",
      "Epoch: 5, itet: 384, loss: 0.1588356.\n",
      "Epoch: 5, itet: 448, loss: 0.0006104.\n",
      "Epoch: 5, itet: 512, loss: 0.3678403.\n",
      "Epoch: 5, itet: 576, loss: 0.0019664.\n",
      "Epoch: 5, itet: 640, loss: 0.0002866.\n",
      "Epoch: 5, acc: 0.817.\n",
      "Epoch: 6, itet: 64, loss: 0.4953375.\n",
      "Epoch: 6, itet: 128, loss: 0.0000948.\n",
      "Epoch: 6, itet: 192, loss: 1.6262116.\n",
      "Epoch: 6, itet: 256, loss: 0.7514824.\n",
      "Epoch: 6, itet: 320, loss: 0.1195844.\n",
      "Epoch: 6, itet: 384, loss: 0.0521670.\n",
      "Epoch: 6, itet: 448, loss: 1.0761868.\n",
      "Epoch: 6, itet: 512, loss: 0.5536926.\n",
      "Epoch: 6, itet: 576, loss: 0.0000973.\n",
      "Epoch: 6, itet: 640, loss: 1.5632998.\n",
      "Epoch: 6, acc: 0.843.\n",
      "Epoch: 7, itet: 64, loss: 0.4396090.\n",
      "Epoch: 7, itet: 128, loss: 0.0607039.\n",
      "Epoch: 7, itet: 192, loss: 0.2280987.\n",
      "Epoch: 7, itet: 256, loss: 0.0004825.\n",
      "Epoch: 7, itet: 320, loss: 0.0812233.\n",
      "Epoch: 7, itet: 384, loss: 0.0607760.\n",
      "Epoch: 7, itet: 448, loss: -0.0000010.\n",
      "Epoch: 7, itet: 512, loss: 0.0168755.\n",
      "Epoch: 7, itet: 576, loss: -0.0000010.\n",
      "Epoch: 7, itet: 640, loss: -0.0000010.\n",
      "Epoch: 7, acc: 1.000.\n",
      "Epoch: 8, itet: 64, loss: 0.0000011.\n",
      "Epoch: 8, itet: 128, loss: -0.0000010.\n",
      "Epoch: 8, itet: 192, loss: -0.0000010.\n",
      "Epoch: 8, itet: 256, loss: -0.0000010.\n",
      "Epoch: 8, itet: 320, loss: 0.0006572.\n",
      "Epoch: 8, itet: 384, loss: 0.0005590.\n",
      "Epoch: 8, itet: 448, loss: -0.0000010.\n",
      "Epoch: 8, itet: 512, loss: 0.0002727.\n",
      "Epoch: 8, itet: 576, loss: -0.0000010.\n",
      "Epoch: 8, itet: 640, loss: -0.0000010.\n",
      "Epoch: 8, acc: 1.000.\n",
      "Epoch: 9, itet: 64, loss: -0.0000010.\n",
      "Epoch: 9, itet: 128, loss: -0.0000010.\n",
      "Epoch: 9, itet: 192, loss: -0.0000010.\n",
      "Epoch: 9, itet: 256, loss: -0.0000010.\n",
      "Epoch: 9, itet: 320, loss: 0.0001612.\n",
      "Epoch: 9, itet: 384, loss: 0.0000394.\n",
      "Epoch: 9, itet: 448, loss: -0.0000010.\n",
      "Epoch: 9, itet: 512, loss: 0.0003562.\n",
      "Epoch: 9, itet: 576, loss: -0.0000010.\n",
      "Epoch: 9, itet: 640, loss: -0.0000010.\n",
      "Epoch: 9, acc: 1.000.\n",
      "Epoch: 10, itet: 64, loss: 0.0003712.\n",
      "Epoch: 10, itet: 128, loss: -0.0000010.\n",
      "Epoch: 10, itet: 192, loss: -0.0000010.\n",
      "Epoch: 10, itet: 256, loss: -0.0000010.\n",
      "Epoch: 10, itet: 320, loss: 0.0000599.\n",
      "Epoch: 10, itet: 384, loss: 0.0002841.\n",
      "Epoch: 10, itet: 448, loss: 0.0000348.\n",
      "Epoch: 10, itet: 512, loss: 0.0000210.\n",
      "Epoch: 10, itet: 576, loss: -0.0000010.\n",
      "Epoch: 10, itet: 640, loss: -0.0000010.\n",
      "Epoch: 10, acc: 1.000.\n",
      "Epoch: 11, itet: 64, loss: 0.0000091.\n",
      "Epoch: 11, itet: 128, loss: -0.0000010.\n",
      "Epoch: 11, itet: 192, loss: -0.0000010.\n",
      "Epoch: 11, itet: 256, loss: -0.0000010.\n",
      "Epoch: 11, itet: 320, loss: 0.0000958.\n",
      "Epoch: 11, itet: 384, loss: -0.0000010.\n",
      "Epoch: 11, itet: 448, loss: -0.0000008.\n",
      "Epoch: 11, itet: 512, loss: 0.0001968.\n",
      "Epoch: 11, itet: 576, loss: -0.0000010.\n",
      "Epoch: 11, itet: 640, loss: -0.0000010.\n",
      "Epoch: 11, acc: 1.000.\n",
      "Epoch: 12, itet: 64, loss: 0.0001465.\n",
      "Epoch: 12, itet: 128, loss: -0.0000010.\n",
      "Epoch: 12, itet: 192, loss: -0.0000010.\n",
      "Epoch: 12, itet: 256, loss: -0.0000010.\n",
      "Epoch: 12, itet: 320, loss: 0.0000278.\n",
      "Epoch: 12, itet: 384, loss: 0.0001351.\n",
      "Epoch: 12, itet: 448, loss: -0.0000010.\n",
      "Epoch: 12, itet: 512, loss: 0.0000232.\n",
      "Epoch: 12, itet: 576, loss: -0.0000008.\n",
      "Epoch: 12, itet: 640, loss: -0.0000010.\n",
      "Epoch: 12, acc: 1.000.\n",
      "Epoch: 13, itet: 64, loss: 0.0002707.\n",
      "Epoch: 13, itet: 128, loss: -0.0000010.\n",
      "Epoch: 13, itet: 192, loss: -0.0000010.\n",
      "Epoch: 13, itet: 256, loss: -0.0000010.\n",
      "Epoch: 13, itet: 320, loss: 0.0000009.\n",
      "Epoch: 13, itet: 384, loss: 0.0001135.\n",
      "Epoch: 13, itet: 448, loss: -0.0000010.\n",
      "Epoch: 13, itet: 512, loss: -0.0000010.\n",
      "Epoch: 13, itet: 576, loss: -0.0000010.\n",
      "Epoch: 13, itet: 640, loss: -0.0000010.\n",
      "Epoch: 13, acc: 1.000.\n",
      "Epoch: 14, itet: 64, loss: 0.0000013.\n",
      "Epoch: 14, itet: 128, loss: -0.0000010.\n",
      "Epoch: 14, itet: 192, loss: -0.0000010.\n",
      "Epoch: 14, itet: 256, loss: -0.0000010.\n",
      "Epoch: 14, itet: 320, loss: -0.0000010.\n",
      "Epoch: 14, itet: 384, loss: 0.0000750.\n",
      "Epoch: 14, itet: 448, loss: -0.0000010.\n",
      "Epoch: 14, itet: 512, loss: 0.0000201.\n",
      "Epoch: 14, itet: 576, loss: -0.0000010.\n",
      "Epoch: 14, itet: 640, loss: -0.0000010.\n",
      "Epoch: 14, acc: 1.000.\n",
      "Epoch: 15, itet: 64, loss: -0.0000010.\n",
      "Epoch: 15, itet: 128, loss: -0.0000010.\n",
      "Epoch: 15, itet: 192, loss: -0.0000010.\n",
      "Epoch: 15, itet: 256, loss: -0.0000010.\n",
      "Epoch: 15, itet: 320, loss: 0.0000020.\n",
      "Epoch: 15, itet: 384, loss: 0.0000170.\n",
      "Epoch: 15, itet: 448, loss: -0.0000010.\n",
      "Epoch: 15, itet: 512, loss: 0.0000409.\n",
      "Epoch: 15, itet: 576, loss: -0.0000010.\n",
      "Epoch: 15, itet: 640, loss: -0.0000010.\n",
      "Epoch: 15, acc: 1.000.\n",
      "Epoch: 16, itet: 64, loss: 0.0000214.\n",
      "Epoch: 16, itet: 128, loss: -0.0000010.\n",
      "Epoch: 16, itet: 192, loss: -0.0000010.\n",
      "Epoch: 16, itet: 256, loss: -0.0000010.\n",
      "Epoch: 16, itet: 320, loss: 0.0000013.\n",
      "Epoch: 16, itet: 384, loss: 0.0000041.\n",
      "Epoch: 16, itet: 448, loss: -0.0000010.\n",
      "Epoch: 16, itet: 512, loss: 0.0000066.\n",
      "Epoch: 16, itet: 576, loss: -0.0000010.\n",
      "Epoch: 16, itet: 640, loss: -0.0000010.\n",
      "Epoch: 16, acc: 1.000.\n",
      "Epoch: 17, itet: 64, loss: 0.0000054.\n",
      "Epoch: 17, itet: 128, loss: -0.0000010.\n",
      "Epoch: 17, itet: 192, loss: -0.0000010.\n",
      "Epoch: 17, itet: 256, loss: -0.0000010.\n",
      "Epoch: 17, itet: 320, loss: 0.0000003.\n",
      "Epoch: 17, itet: 384, loss: 0.0000235.\n",
      "Epoch: 17, itet: 448, loss: -0.0000010.\n",
      "Epoch: 17, itet: 512, loss: 0.0000056.\n",
      "Epoch: 17, itet: 576, loss: -0.0000010.\n",
      "Epoch: 17, itet: 640, loss: -0.0000007.\n",
      "Epoch: 17, acc: 1.000.\n",
      "Epoch: 18, itet: 64, loss: -0.0000002.\n",
      "Epoch: 18, itet: 128, loss: -0.0000010.\n",
      "Epoch: 18, itet: 192, loss: -0.0000010.\n",
      "Epoch: 18, itet: 256, loss: -0.0000010.\n",
      "Epoch: 18, itet: 320, loss: -0.0000007.\n",
      "Epoch: 18, itet: 384, loss: -0.0000007.\n",
      "Epoch: 18, itet: 448, loss: -0.0000010.\n",
      "Epoch: 18, itet: 512, loss: 0.0000041.\n",
      "Epoch: 18, itet: 576, loss: -0.0000010.\n",
      "Epoch: 18, itet: 640, loss: -0.0000010.\n",
      "Epoch: 18, acc: 1.000.\n",
      "Epoch: 19, itet: 64, loss: 0.0000083.\n",
      "Epoch: 19, itet: 128, loss: -0.0000010.\n",
      "Epoch: 19, itet: 192, loss: -0.0000010.\n",
      "Epoch: 19, itet: 256, loss: -0.0000010.\n",
      "Epoch: 19, itet: 320, loss: -0.0000002.\n",
      "Epoch: 19, itet: 384, loss: -0.0000005.\n",
      "Epoch: 19, itet: 448, loss: -0.0000010.\n",
      "Epoch: 19, itet: 512, loss: 0.0000124.\n",
      "Epoch: 19, itet: 576, loss: -0.0000010.\n",
      "Epoch: 19, itet: 640, loss: -0.0000010.\n",
      "Epoch: 19, acc: 1.000.\n",
      "Epoch: 20, itet: 64, loss: -0.0000010.\n",
      "Epoch: 20, itet: 128, loss: 0.0000001.\n",
      "Epoch: 20, itet: 192, loss: -0.0000010.\n",
      "Epoch: 20, itet: 256, loss: -0.0000010.\n",
      "Epoch: 20, itet: 320, loss: -0.0000010.\n",
      "Epoch: 20, itet: 384, loss: 0.0000030.\n",
      "Epoch: 20, itet: 448, loss: 0.0000396.\n",
      "Epoch: 20, itet: 512, loss: -0.0000002.\n",
      "Epoch: 20, itet: 576, loss: -0.0000010.\n",
      "Epoch: 20, itet: 640, loss: -0.0000010.\n",
      "Epoch: 20, acc: 1.000.\n",
      "Epoch: 21, itet: 64, loss: 0.0000033.\n",
      "Epoch: 21, itet: 128, loss: -0.0000010.\n",
      "Epoch: 21, itet: 192, loss: -0.0000010.\n",
      "Epoch: 21, itet: 256, loss: -0.0000010.\n",
      "Epoch: 21, itet: 320, loss: 0.0000007.\n",
      "Epoch: 21, itet: 384, loss: -0.0000006.\n",
      "Epoch: 21, itet: 448, loss: -0.0000010.\n",
      "Epoch: 21, itet: 512, loss: -0.0000010.\n",
      "Epoch: 21, itet: 576, loss: -0.0000010.\n",
      "Epoch: 21, itet: 640, loss: -0.0000010.\n",
      "Epoch: 21, acc: 1.000.\n",
      "Epoch: 22, itet: 64, loss: -0.0000010.\n",
      "Epoch: 22, itet: 128, loss: -0.0000010.\n",
      "Epoch: 22, itet: 192, loss: -0.0000010.\n",
      "Epoch: 22, itet: 256, loss: -0.0000010.\n",
      "Epoch: 22, itet: 320, loss: -0.0000006.\n",
      "Epoch: 22, itet: 384, loss: -0.0000010.\n",
      "Epoch: 22, itet: 448, loss: -0.0000010.\n",
      "Epoch: 22, itet: 512, loss: 0.0000001.\n",
      "Epoch: 22, itet: 576, loss: -0.0000010.\n",
      "Epoch: 22, itet: 640, loss: -0.0000010.\n",
      "Epoch: 22, acc: 1.000.\n",
      "Epoch: 23, itet: 64, loss: -0.0000010.\n",
      "Epoch: 23, itet: 128, loss: -0.0000010.\n",
      "Epoch: 23, itet: 192, loss: -0.0000010.\n",
      "Epoch: 23, itet: 256, loss: -0.0000010.\n",
      "Epoch: 23, itet: 320, loss: -0.0000010.\n",
      "Epoch: 23, itet: 384, loss: -0.0000010.\n",
      "Epoch: 23, itet: 448, loss: -0.0000010.\n",
      "Epoch: 23, itet: 512, loss: -0.0000008.\n",
      "Epoch: 23, itet: 576, loss: -0.0000010.\n",
      "Epoch: 23, itet: 640, loss: -0.0000010.\n",
      "Epoch: 23, acc: 1.000.\n",
      "Epoch: 24, itet: 64, loss: -0.0000007.\n",
      "Epoch: 24, itet: 128, loss: -0.0000010.\n",
      "Epoch: 24, itet: 192, loss: -0.0000010.\n",
      "Epoch: 24, itet: 256, loss: -0.0000010.\n",
      "Epoch: 24, itet: 320, loss: -0.0000010.\n",
      "Epoch: 24, itet: 384, loss: -0.0000010.\n",
      "Epoch: 24, itet: 448, loss: -0.0000010.\n",
      "Epoch: 24, itet: 512, loss: -0.0000010.\n",
      "Epoch: 24, itet: 576, loss: -0.0000010.\n",
      "Epoch: 24, itet: 640, loss: -0.0000010.\n",
      "Epoch: 24, acc: 1.000.\n",
      "Epoch: 25, itet: 64, loss: -0.0000010.\n",
      "Epoch: 25, itet: 128, loss: -0.0000010.\n",
      "Epoch: 25, itet: 192, loss: -0.0000010.\n",
      "Epoch: 25, itet: 256, loss: -0.0000010.\n",
      "Epoch: 25, itet: 320, loss: -0.0000010.\n",
      "Epoch: 25, itet: 384, loss: -0.0000010.\n",
      "Epoch: 25, itet: 448, loss: -0.0000010.\n",
      "Epoch: 25, itet: 512, loss: -0.0000010.\n",
      "Epoch: 25, itet: 576, loss: -0.0000007.\n",
      "Epoch: 25, itet: 640, loss: -0.0000010.\n",
      "Epoch: 25, acc: 1.000.\n",
      "Epoch: 26, itet: 64, loss: 0.0000024.\n",
      "Epoch: 26, itet: 128, loss: -0.0000010.\n",
      "Epoch: 26, itet: 192, loss: -0.0000010.\n",
      "Epoch: 26, itet: 256, loss: -0.0000010.\n",
      "Epoch: 26, itet: 320, loss: -0.0000007.\n",
      "Epoch: 26, itet: 384, loss: -0.0000010.\n",
      "Epoch: 26, itet: 448, loss: -0.0000010.\n",
      "Epoch: 26, itet: 512, loss: -0.0000010.\n",
      "Epoch: 26, itet: 576, loss: -0.0000010.\n",
      "Epoch: 26, itet: 640, loss: -0.0000010.\n",
      "Epoch: 26, acc: 1.000.\n",
      "Epoch: 27, itet: 64, loss: -0.0000010.\n",
      "Epoch: 27, itet: 128, loss: -0.0000010.\n",
      "Epoch: 27, itet: 192, loss: -0.0000010.\n",
      "Epoch: 27, itet: 256, loss: -0.0000010.\n",
      "Epoch: 27, itet: 320, loss: -0.0000010.\n",
      "Epoch: 27, itet: 384, loss: -0.0000010.\n",
      "Epoch: 27, itet: 448, loss: -0.0000010.\n",
      "Epoch: 27, itet: 512, loss: -0.0000010.\n",
      "Epoch: 27, itet: 576, loss: -0.0000010.\n",
      "Epoch: 27, itet: 640, loss: -0.0000010.\n",
      "Epoch: 27, acc: 1.000.\n",
      "Epoch: 28, itet: 64, loss: -0.0000010.\n",
      "Epoch: 28, itet: 128, loss: -0.0000010.\n",
      "Epoch: 28, itet: 192, loss: -0.0000010.\n",
      "Epoch: 28, itet: 256, loss: -0.0000010.\n",
      "Epoch: 28, itet: 320, loss: -0.0000010.\n",
      "Epoch: 28, itet: 384, loss: -0.0000010.\n",
      "Epoch: 28, itet: 448, loss: -0.0000010.\n",
      "Epoch: 28, itet: 512, loss: -0.0000010.\n",
      "Epoch: 28, itet: 576, loss: -0.0000010.\n",
      "Epoch: 28, itet: 640, loss: -0.0000010.\n",
      "Epoch: 28, acc: 1.000.\n",
      "Epoch: 29, itet: 64, loss: -0.0000010.\n",
      "Epoch: 29, itet: 128, loss: -0.0000010.\n",
      "Epoch: 29, itet: 192, loss: -0.0000010.\n",
      "Epoch: 29, itet: 256, loss: -0.0000010.\n",
      "Epoch: 29, itet: 320, loss: -0.0000010.\n",
      "Epoch: 29, itet: 384, loss: -0.0000006.\n",
      "Epoch: 29, itet: 448, loss: -0.0000010.\n",
      "Epoch: 29, itet: 512, loss: -0.0000010.\n",
      "Epoch: 29, itet: 576, loss: -0.0000010.\n",
      "Epoch: 29, itet: 640, loss: -0.0000010.\n",
      "Epoch: 29, acc: 1.000.\n",
      "Epoch: 30, itet: 64, loss: -0.0000010.\n",
      "Epoch: 30, itet: 128, loss: -0.0000010.\n",
      "Epoch: 30, itet: 192, loss: -0.0000010.\n",
      "Epoch: 30, itet: 256, loss: -0.0000010.\n",
      "Epoch: 30, itet: 320, loss: -0.0000010.\n",
      "Epoch: 30, itet: 384, loss: -0.0000010.\n",
      "Epoch: 30, itet: 448, loss: -0.0000000.\n",
      "Epoch: 30, itet: 512, loss: -0.0000010.\n",
      "Epoch: 30, itet: 576, loss: -0.0000010.\n",
      "Epoch: 30, itet: 640, loss: -0.0000010.\n",
      "Epoch: 30, acc: 1.000.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "import numpy as np\n",
    "from mflow import core, ops, opts, lays\n",
    "\n",
    "# 超参数\n",
    "lr = 0.005\n",
    "epoch = 30\n",
    "batch_size = 16\n",
    "\n",
    "with core.NameScope(\"RNNWelding\"):\n",
    "    # 初始化变量\n",
    "    inputs = [core.Variable(size=(in_dim, 1), trainable=False) for _ in range(seq_len)]\n",
    "    u = core.Variable(size=(state_dim, in_dim), trainable=True)\n",
    "    w = core.Variable(size=(state_dim, state_dim), trainable=True)\n",
    "    b = core.Variable(size=(state_dim, 1), trainable=True)\n",
    "    y = core.Variable(size=(2, 1), trainable=False)\n",
    "    last_step = None\n",
    "    hiddens = []\n",
    "    # 网络构建\n",
    "    for iv in inputs:\n",
    "        h = ops.Add(ops.MatMal(u, iv), b)\n",
    "        if last_step is not None:\n",
    "            h = ops.Add(ops.MatMal(w, last_step), h)\n",
    "        h = ops.ReLU(h)\n",
    "        last_step = h\n",
    "        hiddens.append(last_step)\n",
    "    # 焊接点\n",
    "    welding_point = ops.Welding()\n",
    "    # 全连接网络\n",
    "    fc_1 = lays.Linear(welding_point, state_dim, 40, \"ReLU\")\n",
    "    fc_2 = lays.Linear(fc_1, 40, 10, \"ReLU\")\n",
    "    pred = lays.Linear(fc_2, 10, 2, None)\n",
    "    predicter = ops.Logistic(pred)\n",
    "    loss = ops.loss.CrossEntropyWithSoftMax(pred, y)\n",
    "    loss.eps = 1e-6  # 避免梯度消失\n",
    "    adam = opts.Adam(core.DefaultGraph, loss, lr)\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        bs_idx = 0  # 批次计数\n",
    "        # 这是一个epoch的过程\n",
    "        for i, (feat, lab) in enumerate(zip(train_xs, train_ys)):\n",
    "            # 取变长序列\n",
    "            lens = len(feat)\n",
    "            start = np.random.randint(lens // 3)\n",
    "            end = np.random.randint(lens // 3 + 30, lens)\n",
    "            feat = feat[start: end]\n",
    "            # 变长输入进入向量节点\n",
    "            for j in range(len(feat)):\n",
    "                inputs[j].setValue(np.mat(feat[j]).T)\n",
    "            # 网络焊接\n",
    "            welding_point.weld(hiddens[j])\n",
    "            y.setValue(np.mat(lab).T)\n",
    "            adam.step()\n",
    "            bs_idx += 1\n",
    "            if bs_idx == batch_size:\n",
    "                if (i + 1) % 64 == 0:\n",
    "                    print(\"Epoch: {:d}, itet: {:d}, loss: {:.7f}.\".format(\n",
    "                        ep, i + 1, loss.value[0, 0]))\n",
    "                adam.update()\n",
    "                bs_idx = 0\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for feat in test_xs:\n",
    "            lens = len(feat)\n",
    "            start = np.random.randint(lens // 3)\n",
    "            end = np.random.randint(lens // 3 + 30, lens)\n",
    "            feat = feat[start: end]\n",
    "            for j in range(len(feat)):\n",
    "                inputs[j].setValue(np.mat(feat[j]).T)\n",
    "            welding_point.weld(hiddens[j])\n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value.A.ravel())  # 结果\n",
    "        preds = np.array(preds).argmax(axis=1)\n",
    "        trues = test_ys.argmax(axis=1)\n",
    "        acc = (trues == preds).astype(\"uint8\").sum() / len(test_xs)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25450dffbd8ff6afdb60e6b8570ed9b7d168b4425452c653cc1a70a36de1a45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
