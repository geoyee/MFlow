{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "[[163.45521003  45.72651572  21.69441371  -1.        ]\n",
      " [166.81979752  82.81856221  17.25039533   1.        ]\n",
      " [170.68315035  70.88920833  12.481461     1.        ]\n",
      " ...\n",
      " [160.74395607  61.20629333  24.16423492  -1.        ]\n",
      " [181.08597064  65.19729623  14.96382981   1.        ]\n",
      " [177.76128716  75.06965252  16.60629143   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "import numpy as np\n",
    "\n",
    "# 生成男性数据\n",
    "male = {\n",
    "    \"height\": np.random.normal(171, 6, 500),  # 身高\n",
    "    \"weight\": np.random.normal(70, 10, 500),  # 体重\n",
    "    \"bfr\": np.random.normal(16, 2, 500),  # 体脂率\n",
    "    \"label\": [1] * 500  # 标签\n",
    "}\n",
    "\n",
    "# 生成女性数据\n",
    "female = {\n",
    "    \"height\": np.random.normal(158, 5, 500),\n",
    "    \"weight\": np.random.normal(57, 8, 500),\n",
    "    \"bfr\": np.random.normal(22, 2, 500),\n",
    "    \"label\": [-1] * 500\n",
    "}\n",
    "\n",
    "# 训练数据\n",
    "train_data = np.array([\n",
    "    np.concatenate((male[\"height\"], female[\"height\"])),\n",
    "    np.concatenate((male[\"weight\"], female[\"weight\"])),\n",
    "    np.concatenate((male[\"bfr\"], female[\"bfr\"])),\n",
    "    np.concatenate((male[\"label\"], female[\"label\"]))\n",
    "]).T\n",
    "np.random.shuffle(train_data)  # 打乱数据\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, acc: 0.511.\n",
      "Epoch: 2, acc: 0.932.\n",
      "Epoch: 3, acc: 0.950.\n",
      "Epoch: 4, acc: 0.873.\n",
      "Epoch: 5, acc: 0.869.\n",
      "Epoch: 6, acc: 0.901.\n",
      "Epoch: 7, acc: 0.926.\n",
      "Epoch: 8, acc: 0.944.\n",
      "Epoch: 9, acc: 0.899.\n",
      "Epoch: 10, acc: 0.932.\n",
      "Epoch: 11, acc: 0.918.\n",
      "Epoch: 12, acc: 0.950.\n",
      "Epoch: 13, acc: 0.947.\n",
      "Epoch: 14, acc: 0.944.\n",
      "Epoch: 15, acc: 0.935.\n",
      "Epoch: 16, acc: 0.946.\n",
      "Epoch: 17, acc: 0.949.\n",
      "Epoch: 18, acc: 0.948.\n",
      "Epoch: 19, acc: 0.957.\n",
      "Epoch: 20, acc: 0.954.\n",
      "Epoch: 21, acc: 0.964.\n",
      "Epoch: 22, acc: 0.962.\n",
      "Epoch: 23, acc: 0.962.\n",
      "Epoch: 24, acc: 0.964.\n",
      "Epoch: 25, acc: 0.964.\n",
      "Epoch: 26, acc: 0.968.\n",
      "Epoch: 27, acc: 0.964.\n",
      "Epoch: 28, acc: 0.968.\n",
      "Epoch: 29, acc: 0.967.\n",
      "Epoch: 30, acc: 0.965.\n",
      "Epoch: 31, acc: 0.969.\n",
      "Epoch: 32, acc: 0.968.\n",
      "Epoch: 33, acc: 0.971.\n",
      "Epoch: 34, acc: 0.968.\n",
      "Epoch: 35, acc: 0.967.\n",
      "Epoch: 36, acc: 0.966.\n",
      "Epoch: 37, acc: 0.971.\n",
      "Epoch: 38, acc: 0.966.\n",
      "Epoch: 39, acc: 0.971.\n",
      "Epoch: 40, acc: 0.969.\n",
      "Epoch: 41, acc: 0.971.\n",
      "Epoch: 42, acc: 0.969.\n",
      "Epoch: 43, acc: 0.970.\n",
      "Epoch: 44, acc: 0.971.\n",
      "Epoch: 45, acc: 0.970.\n",
      "Epoch: 46, acc: 0.971.\n",
      "Epoch: 47, acc: 0.970.\n",
      "Epoch: 48, acc: 0.970.\n",
      "Epoch: 49, acc: 0.971.\n",
      "Epoch: 50, acc: 0.970.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from mflow import core, ops\n",
    "\n",
    "# 超参数\n",
    "lr = 0.0001\n",
    "epoch = 50\n",
    "\n",
    "with core.NameScope(\"ADALINE\"):\n",
    "    # 初始化变量\n",
    "    x = core.Variable(size=(3, 1), trainable=False)\n",
    "    y = core.Variable(size=(1, 1), trainable=False)\n",
    "    w = core.Variable(size=(1, 3), trainable=True)\n",
    "    b = core.Variable(size=(1, 1), trainable=True)\n",
    "    # 模型定义\n",
    "    pred = ops.Add(ops.MatMal(w, x), b)\n",
    "    predicter = ops.Step(pred)\n",
    "    loss = ops.loss.PerceptionLoss(ops.MatMal(y, pred))\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        # 这是一个epoch的过程\n",
    "        for data in train_data:\n",
    "            x.setValue(np.mat(data[:-1]).T)\n",
    "            y.setValue(np.mat(data[-1]))\n",
    "            # 前向\n",
    "            loss.forward()\n",
    "            # 反向\n",
    "            w.backward(loss)\n",
    "            b.backward(loss)\n",
    "            # 更新参数\n",
    "            w.step(lr)\n",
    "            b.step(lr)\n",
    "            # 清除图中的jacobi\n",
    "            core.DefaultGraph.clearAllJacobis()\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for data in train_data:\n",
    "            x.setValue(np.mat(data[:-1]).T)\n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value[0, 0])  # 结果\n",
    "        preds = np.array(preds) * 2 - 1  # 0/1转为-1/1\n",
    "        acc = (train_data[:, -1] == preds).astype(\"uint8\").sum() / len(train_data)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25450dffbd8ff6afdb60e6b8570ed9b7d168b4425452c653cc1a70a36de1a45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
