{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "[[164.26310835  55.93403323  21.15938099  -1.        ]\n",
      " [167.9436747   65.03795909  16.83634029   1.        ]\n",
      " [174.96691709  75.2623049   18.12819751   1.        ]\n",
      " ...\n",
      " [160.19576109  59.49484938  21.38799803  -1.        ]\n",
      " [177.08489204  66.9367337   10.30163415   1.        ]\n",
      " [162.64241359  54.22057884  20.37421834  -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "import numpy as np\n",
    "\n",
    "# 生成男性数据\n",
    "male = {\n",
    "    \"height\": np.random.normal(171, 6, 500),  # 身高\n",
    "    \"weight\": np.random.normal(70, 10, 500),  # 体重\n",
    "    \"bfr\": np.random.normal(16, 2, 500),  # 体脂率\n",
    "    \"label\": [1] * 500  # 标签\n",
    "}\n",
    "\n",
    "# 生成女性数据\n",
    "female = {\n",
    "    \"height\": np.random.normal(158, 5, 500),\n",
    "    \"weight\": np.random.normal(57, 8, 500),\n",
    "    \"bfr\": np.random.normal(22, 2, 500),\n",
    "    \"label\": [-1] * 500\n",
    "}\n",
    "\n",
    "# 训练数据\n",
    "train_data = np.array([\n",
    "    np.concatenate((male[\"height\"], female[\"height\"])),\n",
    "    np.concatenate((male[\"weight\"], female[\"weight\"])),\n",
    "    np.concatenate((male[\"bfr\"], female[\"bfr\"])),\n",
    "    np.concatenate((male[\"label\"], female[\"label\"]))\n",
    "]).T\n",
    "np.random.shuffle(train_data)  # 打乱数据\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, acc: 0.500.\n",
      "Epoch: 2, acc: 0.508.\n",
      "Epoch: 3, acc: 0.567.\n",
      "Epoch: 4, acc: 0.646.\n",
      "Epoch: 5, acc: 0.710.\n",
      "Epoch: 6, acc: 0.762.\n",
      "Epoch: 7, acc: 0.798.\n",
      "Epoch: 8, acc: 0.822.\n",
      "Epoch: 9, acc: 0.846.\n",
      "Epoch: 10, acc: 0.861.\n",
      "Epoch: 11, acc: 0.869.\n",
      "Epoch: 12, acc: 0.880.\n",
      "Epoch: 13, acc: 0.885.\n",
      "Epoch: 14, acc: 0.888.\n",
      "Epoch: 15, acc: 0.891.\n",
      "Epoch: 16, acc: 0.897.\n",
      "Epoch: 17, acc: 0.900.\n",
      "Epoch: 18, acc: 0.900.\n",
      "Epoch: 19, acc: 0.905.\n",
      "Epoch: 20, acc: 0.906.\n",
      "Epoch: 21, acc: 0.905.\n",
      "Epoch: 22, acc: 0.910.\n",
      "Epoch: 23, acc: 0.911.\n",
      "Epoch: 24, acc: 0.913.\n",
      "Epoch: 25, acc: 0.914.\n",
      "Epoch: 26, acc: 0.913.\n",
      "Epoch: 27, acc: 0.916.\n",
      "Epoch: 28, acc: 0.916.\n",
      "Epoch: 29, acc: 0.920.\n",
      "Epoch: 30, acc: 0.921.\n",
      "Epoch: 31, acc: 0.921.\n",
      "Epoch: 32, acc: 0.922.\n",
      "Epoch: 33, acc: 0.925.\n",
      "Epoch: 34, acc: 0.926.\n",
      "Epoch: 35, acc: 0.928.\n",
      "Epoch: 36, acc: 0.928.\n",
      "Epoch: 37, acc: 0.929.\n",
      "Epoch: 38, acc: 0.929.\n",
      "Epoch: 39, acc: 0.929.\n",
      "Epoch: 40, acc: 0.929.\n",
      "Epoch: 41, acc: 0.929.\n",
      "Epoch: 42, acc: 0.930.\n",
      "Epoch: 43, acc: 0.932.\n",
      "Epoch: 44, acc: 0.932.\n",
      "Epoch: 45, acc: 0.931.\n",
      "Epoch: 46, acc: 0.931.\n",
      "Epoch: 47, acc: 0.932.\n",
      "Epoch: 48, acc: 0.933.\n",
      "Epoch: 49, acc: 0.933.\n",
      "Epoch: 50, acc: 0.934.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from mflow import core, ops, opts\n",
    "\n",
    "# 超参数\n",
    "lr = 0.0001\n",
    "epoch = 50\n",
    "batch_size = 16\n",
    "\n",
    "with core.NameScope(\"LogisticRegression\"):\n",
    "    # 初始化变量\n",
    "    x = core.Variable(size=(3, 1), trainable=False)\n",
    "    y = core.Variable(size=(1, 1), trainable=False)\n",
    "    w = core.Variable(size=(1, 3), trainable=True)\n",
    "    b = core.Variable(size=(1, 1), trainable=True)\n",
    "    # 模型定义\n",
    "    pred = ops.Add(ops.MatMal(w, x), b)\n",
    "    predicter = ops.Logistic(pred)\n",
    "    loss = ops.loss.LogLoss(ops.Multiply(y, pred))\n",
    "    adam = opts.Adam(core.DefaultGraph, loss, lr)\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        bs_idx = 0  # 批次计数\n",
    "        # 这是一个epoch的过程\n",
    "        for i, data in enumerate(train_data):\n",
    "            x.setValue(np.mat(data[:-1]).T)\n",
    "            y.setValue(np.mat(data[-1]))\n",
    "            adam.step()\n",
    "            bs_idx += 1\n",
    "            if bs_idx == batch_size:\n",
    "                adam.update()\n",
    "                bs_idx = 0\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for data in train_data:\n",
    "            x.setValue(np.mat(data[:-1]).T) \n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value[0, 0])  # 结果\n",
    "        preds = (np.array(preds) > 0.5).astype(\"int\") * 2 - 1  # 0/1转为-1/1\n",
    "        acc = (train_data[:, -1] == preds).astype(\"uint8\").sum() / len(train_data)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25450dffbd8ff6afdb60e6b8570ed9b7d168b4425452c653cc1a70a36de1a45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
