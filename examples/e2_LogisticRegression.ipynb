{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"E:/dataFiles/github/MFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "[[157.59818886  61.86325909  21.58988545  -1.        ]\n",
      " [169.95194504  53.93478935  14.18846771   1.        ]\n",
      " [147.92215393  45.62797978  19.9485315   -1.        ]\n",
      " ...\n",
      " [151.25561587  57.22844816  21.45798935  -1.        ]\n",
      " [178.07085969 100.24792211  19.07196887   1.        ]\n",
      " [154.42453622  67.33939644  21.94970355  -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 数据生成\n",
    "import numpy as np\n",
    "\n",
    "# 生成男性数据\n",
    "male = {\n",
    "    \"height\": np.random.normal(171, 6, 500),  # 身高\n",
    "    \"weight\": np.random.normal(70, 10, 500),  # 体重\n",
    "    \"bfr\": np.random.normal(16, 2, 500),  # 体脂率\n",
    "    \"label\": [1] * 500  # 标签\n",
    "}\n",
    "\n",
    "# 生成女性数据\n",
    "female = {\n",
    "    \"height\": np.random.normal(158, 5, 500),\n",
    "    \"weight\": np.random.normal(57, 8, 500),\n",
    "    \"bfr\": np.random.normal(22, 2, 500),\n",
    "    \"label\": [-1] * 500\n",
    "}\n",
    "\n",
    "# 训练数据\n",
    "train_data = np.array([\n",
    "    np.concatenate((male[\"height\"], female[\"height\"])),\n",
    "    np.concatenate((male[\"weight\"], female[\"weight\"])),\n",
    "    np.concatenate((male[\"bfr\"], female[\"bfr\"])),\n",
    "    np.concatenate((male[\"label\"], female[\"label\"]))\n",
    "]).T\n",
    "np.random.shuffle(train_data)  # 打乱数据\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, acc: 0.567.\n",
      "Epoch: 2, acc: 0.894.\n",
      "Epoch: 3, acc: 0.917.\n",
      "Epoch: 4, acc: 0.922.\n",
      "Epoch: 5, acc: 0.929.\n",
      "Epoch: 6, acc: 0.931.\n",
      "Epoch: 7, acc: 0.934.\n",
      "Epoch: 8, acc: 0.938.\n",
      "Epoch: 9, acc: 0.944.\n",
      "Epoch: 10, acc: 0.948.\n",
      "Epoch: 11, acc: 0.951.\n",
      "Epoch: 12, acc: 0.954.\n",
      "Epoch: 13, acc: 0.954.\n",
      "Epoch: 14, acc: 0.957.\n",
      "Epoch: 15, acc: 0.957.\n",
      "Epoch: 16, acc: 0.958.\n",
      "Epoch: 17, acc: 0.960.\n",
      "Epoch: 18, acc: 0.961.\n",
      "Epoch: 19, acc: 0.962.\n",
      "Epoch: 20, acc: 0.962.\n",
      "Epoch: 21, acc: 0.962.\n",
      "Epoch: 22, acc: 0.960.\n",
      "Epoch: 23, acc: 0.961.\n",
      "Epoch: 24, acc: 0.962.\n",
      "Epoch: 25, acc: 0.964.\n",
      "Epoch: 26, acc: 0.965.\n",
      "Epoch: 27, acc: 0.966.\n",
      "Epoch: 28, acc: 0.966.\n",
      "Epoch: 29, acc: 0.966.\n",
      "Epoch: 30, acc: 0.966.\n",
      "Epoch: 31, acc: 0.968.\n",
      "Epoch: 32, acc: 0.968.\n",
      "Epoch: 33, acc: 0.968.\n",
      "Epoch: 34, acc: 0.969.\n",
      "Epoch: 35, acc: 0.969.\n",
      "Epoch: 36, acc: 0.969.\n",
      "Epoch: 37, acc: 0.970.\n",
      "Epoch: 38, acc: 0.970.\n",
      "Epoch: 39, acc: 0.970.\n",
      "Epoch: 40, acc: 0.970.\n",
      "Epoch: 41, acc: 0.970.\n",
      "Epoch: 42, acc: 0.970.\n",
      "Epoch: 43, acc: 0.971.\n",
      "Epoch: 44, acc: 0.971.\n",
      "Epoch: 45, acc: 0.971.\n",
      "Epoch: 46, acc: 0.971.\n",
      "Epoch: 47, acc: 0.971.\n",
      "Epoch: 48, acc: 0.972.\n",
      "Epoch: 49, acc: 0.972.\n",
      "Epoch: 50, acc: 0.972.\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from mflow import core, ops, opts\n",
    "\n",
    "# 超参数\n",
    "lr = 0.001\n",
    "epoch = 50\n",
    "batch_size = 16\n",
    "\n",
    "with core.NameScope(\"LogisticRegression\"):\n",
    "    # 初始化变量\n",
    "    x = core.Variable(size=(3, 1), trainable=False)\n",
    "    y = core.Variable(size=(1, 1), trainable=False)\n",
    "    w = core.Variable(size=(1, 3), trainable=True)\n",
    "    b = core.Variable(size=(1, 1), trainable=True)\n",
    "    # 模型定义\n",
    "    pred = ops.Add(ops.MatMal(w, x), b)\n",
    "    predicter = ops.Logistic(pred)\n",
    "    loss = ops.loss.LogLoss(ops.Multiply(y, pred))\n",
    "    adam = opts.Adam(core.DefaultGraph, loss, lr)\n",
    "    # 开始训练\n",
    "    for ep in range(1, epoch + 1):\n",
    "        bs_idx = 0  # 批次计数\n",
    "        # 这是一个epoch的过程\n",
    "        for i, data in enumerate(train_data):\n",
    "            x.setValue(np.mat(data[:-1]).T)\n",
    "            y.setValue(np.mat(data[-1]))\n",
    "            adam.step()\n",
    "            bs_idx += 1\n",
    "            if bs_idx == batch_size:\n",
    "                adam.update()\n",
    "                bs_idx = 0\n",
    "        # 一个epoch完成后进行评估\n",
    "        preds = []\n",
    "        for data in train_data:\n",
    "            x.setValue(np.mat(data[:-1]).T)\n",
    "            predicter.forward()\n",
    "            preds.append(predicter.value[0, 0])  # 结果\n",
    "        preds = (np.array(preds) > 0.5).astype(\"int\") * 2 - 1  # 0/1转为-1/1\n",
    "        acc = (train_data[:, -1] == preds).astype(\"uint8\").sum() / len(train_data)\n",
    "        print(\"Epoch: {:d}, acc: {:.3f}.\".format(ep, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25450dffbd8ff6afdb60e6b8570ed9b7d168b4425452c653cc1a70a36de1a45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('iann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
